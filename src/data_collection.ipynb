{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "403 Client Error: FORBIDDEN for url: https://api.openalex.org/works?select=id,doi,title,publication_year,primary_topic,referenced_works_count,referenced_works,cited_by_api_url&filter=authorships.countries:countries/br,primary_topic.field.id:fields/17,publication_year:2024,%20authorships.institutions.lineage:i52418104&sort=publication_year:desc&mailto=vinemioto@gmail.com&page=1&per_page=10&mailto=vinemioto@gmail.com",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 162\u001b[0m\n\u001b[1;32m    159\u001b[0m logging\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFull API URL with mailto: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, api_url)\n\u001b[1;32m    161\u001b[0m \u001b[38;5;66;03m# Fetch all data (this returns a list of parsed records)\u001b[39;00m\n\u001b[0;32m--> 162\u001b[0m all_results \u001b[38;5;241m=\u001b[39m \u001b[43mfetch_all_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapi_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43memail\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(all_results)\n\u001b[1;32m    164\u001b[0m logging\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData loaded into DataFrame with \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m records.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(df))\n",
      "Cell \u001b[0;32mIn[1], line 109\u001b[0m, in \u001b[0;36mfetch_all_data\u001b[0;34m(base_url, email)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;66;03m# Fetch the first page\u001b[39;00m\n\u001b[1;32m    108\u001b[0m first_page_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m&page=1&per_page=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mper_page\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m&mailto=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00memail\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 109\u001b[0m first_page_data \u001b[38;5;241m=\u001b[39m \u001b[43mfetch_api_data_with_session\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfirst_page_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msession\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m first_page_results \u001b[38;5;241m=\u001b[39m parse_results(first_page_data)\n\u001b[1;32m    111\u001b[0m all_results\u001b[38;5;241m.\u001b[39mextend(first_page_results)\n",
      "Cell \u001b[0;32mIn[1], line 43\u001b[0m, in \u001b[0;36mfetch_api_data_with_session\u001b[0;34m(url, session)\u001b[0m\n\u001b[1;32m     41\u001b[0m response \u001b[38;5;241m=\u001b[39m session\u001b[38;5;241m.\u001b[39mget(url)\n\u001b[1;32m     42\u001b[0m logging\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived response with status code: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, response\u001b[38;5;241m.\u001b[39mstatus_code)\n\u001b[0;32m---> 43\u001b[0m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m data \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson()\n\u001b[1;32m     45\u001b[0m logging\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSuccessfully fetched and parsed API data.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Projects/br_citation_network_cs/.venv/lib/python3.13/site-packages/requests/models.py:1024\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1019\u001b[0m     http_error_msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1020\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Server Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreason\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for url: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1021\u001b[0m     )\n\u001b[1;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1024\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 403 Client Error: FORBIDDEN for url: https://api.openalex.org/works?select=id,doi,title,publication_year,primary_topic,referenced_works_count,referenced_works,cited_by_api_url&filter=authorships.countries:countries/br,primary_topic.field.id:fields/17,publication_year:2024,%20authorships.institutions.lineage:i52418104&sort=publication_year:desc&mailto=vinemioto@gmail.com&page=1&per_page=10&mailto=vinemioto@gmail.com"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "import logging\n",
    "from math import ceil\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# Configure logging to write to debug.log with detailed formatting.\n",
    "logging.basicConfig(\n",
    "    filename='debug.log',\n",
    "    level=logging.DEBUG,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "\n",
    "def get_email():\n",
    "    \"\"\"\n",
    "    Reads the email address from the 'email.json' file.\n",
    "    Returns:\n",
    "        str: The email address.\n",
    "    \"\"\"\n",
    "    logging.debug(\"Attempting to read email from '../.config/email.json'.\")\n",
    "    try:\n",
    "        with open(\"../.config/email.json\", \"r\") as file:\n",
    "            data = json.load(file)\n",
    "        email = data.get(\"email\")\n",
    "        if email:\n",
    "            logging.debug(\"Successfully retrieved email: %s\", email)\n",
    "        else:\n",
    "            logging.warning(\"Email not found in the configuration file.\")\n",
    "        return email\n",
    "    except Exception as e:\n",
    "        logging.exception(\"Error reading the email configuration: %s\", e)\n",
    "        raise\n",
    "\n",
    "def fetch_api_data_with_session(url, session):\n",
    "    \"\"\"\n",
    "    Fetches data from the API using the provided session.\n",
    "    \"\"\"\n",
    "    logging.debug(\"Fetching API data from URL with session: %s\", url)\n",
    "    try:\n",
    "        response = session.get(url)\n",
    "        logging.debug(\"Received response with status code: %s\", response.status_code)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        logging.debug(\"Successfully fetched and parsed API data.\")\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        logging.exception(\"Error fetching API data from %s: %s\", url, e)\n",
    "        raise\n",
    "\n",
    "def parse_results(json_data):\n",
    "    \"\"\"\n",
    "    Parses the JSON data to extract specific fields for each work.\n",
    "    Handles both a dictionary with a \"results\" key and a list of works.\n",
    "    \n",
    "    Returns:\n",
    "        list: A list of dictionaries containing selected fields.\n",
    "    \"\"\"\n",
    "    logging.debug(\"Parsing JSON results.\")\n",
    "    results = []\n",
    "    if isinstance(json_data, dict):\n",
    "        works = json_data.get(\"results\", [])\n",
    "    elif isinstance(json_data, list):\n",
    "        works = json_data\n",
    "    else:\n",
    "        logging.error(\"Unexpected json_data format: %s\", type(json_data))\n",
    "        return results\n",
    "\n",
    "    for work in works:\n",
    "        # Use get(\"id\", \"\") to ensure a string is returned, then remove the prefix.\n",
    "        work_id = work.get(\"id\", \"\").removeprefix(\"https://openalex.org/\")\n",
    "        doi = (work.get(\"doi\") or \"\").removeprefix(\"https://doi.org/\")\n",
    "        title = work.get(\"title\", \"\")\n",
    "        primary_topic = work.get(\"primary_topic\", {})\n",
    "        subfield = primary_topic.get(\"subfield\", {})\n",
    "        subfield_display_name = subfield.get(\"display_name\", \"\")\n",
    "        referenced_works_count = work.get(\"referenced_works_count\", 0)\n",
    "        referenced_works = work.get(\"referenced_works\", [])\n",
    "        cited_by_api_url = work.get(\"cited_by_api_url\", \"\")\n",
    "        \n",
    "        results.append({\n",
    "            \"id\": work_id,\n",
    "            \"doi\": doi,\n",
    "            \"title\": title,\n",
    "            \"subfield_display_name\": subfield_display_name,\n",
    "            \"referenced_works_count\": referenced_works_count,\n",
    "            \"referenced_works\": referenced_works,\n",
    "            \"cited_by_api_url\": cited_by_api_url\n",
    "        })\n",
    "    logging.debug(\"Parsed %s records from JSON data.\", len(results))\n",
    "    return results\n",
    "\n",
    "def fetch_all_data(base_url, email):\n",
    "    \"\"\"\n",
    "    Fetches all data from the API using connection pooling and concurrency.\n",
    "    First, the first page is fetched to determine the total count of records.\n",
    "    Then, remaining pages are fetched concurrently.\n",
    "    \n",
    "    Returns:\n",
    "        list: A combined list of all parsed work records.\n",
    "    \"\"\"\n",
    "    logging.debug(\"Starting to fetch all data from the API using a session.\")\n",
    "    per_page = 10\n",
    "    all_results = []\n",
    "    session = requests.Session()\n",
    "\n",
    "    # Fetch the first page\n",
    "    first_page_url = f\"{base_url}&page=1&per_page={per_page}&mailto={email}\"\n",
    "    first_page_data = fetch_api_data_with_session(first_page_url, session)\n",
    "    first_page_results = parse_results(first_page_data)\n",
    "    all_results.extend(first_page_results)\n",
    "    \n",
    "    # Determine total pages (if meta info is provided)\n",
    "    total_count = None\n",
    "    if isinstance(first_page_data, dict):\n",
    "        meta = first_page_data.get(\"meta\", {})\n",
    "        total_count = meta.get(\"count\")\n",
    "    total_pages = ceil(total_count / per_page) if total_count else 1\n",
    "    logging.debug(\"Total count: %s, Total pages: %s\", total_count, total_pages)\n",
    "\n",
    "    # Fetch remaining pages concurrently if there are more pages\n",
    "    if total_pages > 1:\n",
    "        with ThreadPoolExecutor(max_workers=2) as executor:\n",
    "            futures = []\n",
    "            for page in range(2, total_pages + 1):\n",
    "                page_url = f\"{base_url}&page={page}&per_page={per_page}&mailto={email}\"\n",
    "                logging.debug(\"Submitting fetch for page %s\", page)\n",
    "                futures.append(executor.submit(fetch_api_data_with_session, page_url, session))\n",
    "            for future in as_completed(futures):\n",
    "                page_data = future.result()\n",
    "                page_results = parse_results(page_data)\n",
    "                logging.debug(\"Fetched %s records from a page.\", len(page_results))\n",
    "                all_results.extend(page_results)\n",
    "    logging.debug(\"Completed fetching all data. Total records: %s\", len(all_results))\n",
    "    return all_results\n",
    "\n",
    "# Main execution block\n",
    "if __name__ == \"__main__\":\n",
    "    logging.debug(\"Program started.\")\n",
    "    try:\n",
    "        # Read the email from the file\n",
    "        email = get_email()\n",
    "        if not email:\n",
    "            logging.error(\"Email is required to proceed. Exiting program.\")\n",
    "            exit(1)\n",
    "        \n",
    "        # Define the API endpoint URL (without page and per_page parameters)\n",
    "        base_url = (\n",
    "            \"https://api.openalex.org/works?select=id,doi,title,publication_year,\"\n",
    "            \"primary_topic,referenced_works_count,referenced_works,cited_by_api_url&\"\n",
    "            \"filter=authorships.countries:countries/br,primary_topic.field.id:fields/17,\"\n",
    "            \"publication_year:2024, authorships.institutions.lineage:i52418104\"\n",
    "            \"&sort=publication_year:desc\"\n",
    "        )\n",
    "        \n",
    "        logging.debug(\"Base API URL: %s\", base_url)\n",
    "        # Append the mailto parameter using the email from the file\n",
    "        api_url = f\"{base_url}&mailto={email}\"\n",
    "        logging.debug(\"Full API URL with mailto: %s\", api_url)\n",
    "        \n",
    "        # Fetch all data (this returns a list of parsed records)\n",
    "        all_results = fetch_all_data(api_url, email)\n",
    "        df = pd.DataFrame(all_results)\n",
    "        logging.debug(\"Data loaded into DataFrame with %s records.\", len(df))\n",
    "        \n",
    "        # Optionally, save the DataFrame to a CSV file:\n",
    "        # df.to_csv(\"openalex_data.csv\", index=False)\n",
    "        logging.debug(\"Program completed successfully.\")\n",
    "    except Exception as e:\n",
    "        logging.exception(\"An error occurred during execution: %s\", e)\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"openalex_data.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
